{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17006a17",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "This tutorial will go through how to setup a featurization pipeline in `ralf`. We'll setup a pipeline for computing user features given a data stream of user ratings. We'll then query the user features to predict the rating a user will give a movie. \n",
    "\n",
    "To do so, we'll do the following: \n",
    "1. Create feature tables from the movie lens dataset which are incrementally maintained by `ralf`\n",
    "2. Create a ralf client which queries the feature tables \n",
    "3. Implement load shedding policies to reduce feature computation cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a769d63d",
   "metadata": {},
   "source": [
    "# Creating a featurization pipeline \n",
    "We create a instance of ralf to that we can start creating tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594cfd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ralf import Ralf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05405be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ralf_server = Ralf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644ace1a",
   "metadata": {},
   "source": [
    "### Creating Source Tables\n",
    "Source tables define the raw data sources that are run through ralf to become features. `ralf` lets you create both static batch (e.g. from a CSV) and dynamic streaming sources (e.g. from Kafka). \n",
    "\n",
    "To define a source, we implement a `SourceOperator`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b482acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ralf.operators.source import SourceOperator\n",
    "from ralf import Record\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9df22df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingsSource(SourceOperator):\n",
    "    def __init__(self, schema, kafka_topic):\n",
    "        self.topic = kafka_topic\n",
    "\n",
    "        super().__init__(schema)\n",
    "\n",
    "    def next(self):\n",
    "        time.sleep(0.01)\n",
    "        user_id = random.randint(1, 10)\n",
    "        movie_id = random.randint(100, 200)\n",
    "        rating = random.randint(1, 5)\n",
    "        return [Record(user=str(user_id), movie=movie_id, rating=rating)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f1523f",
   "metadata": {},
   "source": [
    "We specify a schema using ralf's `Schema` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1364670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ralf import Schema\n",
    "\n",
    "source_schema = Schema(\n",
    "    primary_key=\"user\", columns={\"user\": str, \"movie\": int, \"rating\": float}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6199eca",
   "metadata": {},
   "source": [
    "We can now add the source to our ralf instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c678ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = ralf_server.create_source(RatingsSource, args=(source_schema, \"ratings_topic\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3909f7f7",
   "metadata": {},
   "source": [
    "### Creating Feature Tables \n",
    "Now that we have data streaming into ralf through the source table, we can define derived feature tables from the source table. \n",
    "\n",
    "Feature tables follow an API similar to pandas dataframes. We define feature tables in terms of 1-2 parent tables and an operator which specifies how to transform parent data. \n",
    "\n",
    "\n",
    "For example, we can calculate the average rating for each user with an `AverageRating` operator: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84f91ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "from ralf import Operator, Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ac4581",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageRating(Operator):\n",
    "    def __init__(self, schema):\n",
    "        self.user_ratings = defaultdict(list)\n",
    "\n",
    "        super().__init__(schema)\n",
    "\n",
    "    def on_record(self, record: Record):\n",
    "        self.user_ratings[record.user].append(record.rating)\n",
    "        ratings = np.array(self.user_ratings[record.user])\n",
    "        output_record = Record(user=record.user, average=ratings.mean())\n",
    "        return output_record  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c03ecef",
   "metadata": {},
   "source": [
    "The `AverageRating` operator can be used to define a feature table containing the average rating for each user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6f3c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_rating_schema = Schema(\n",
    "    primary_key=\"user\", columns={\"user\": str, \"average\": float}\n",
    ")\n",
    "average_rating = source.map(AverageRating, args=(average_rating_schema,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6651c9",
   "metadata": {},
   "source": [
    "### Adding Processing Policies\n",
    "In many cases, we may only need to sub-sample some of the data to get the features we need. We can add a simple load shedding policy to the `average_rating` table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cf588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ralf import LoadSheddingPolicy, Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d18c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleHalf(LoadSheddingPolicy):\n",
    "    \n",
    "    def process(self, candidate_record: Record, current_record: Record) -> bool:\n",
    "        return random.random() < 0.5\n",
    "\n",
    "average_rating.add_load_shedding(SampleHalf)\n",
    "average_rating.as_queryable(\"average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2757e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "ralf_server.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7715b4b9",
   "metadata": {},
   "source": [
    "## Creating a `ralf` Client \n",
    "Now that we have a simple pipeline, we can query the ralf server for features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbc90c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ralf import RalfClient\n",
    "ralf_client = RalfClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b9cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ralf_client.point_query(table_name=\"average\", key=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbde8a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ralf_client.bulk_query(table_name=\"average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69ee3a4",
   "metadata": {},
   "source": [
    "# Advanced: Maintaining user vectors \n",
    "Now that we've setup a simple feature table and run some queries, we can create a more realistic feature table: a user vector representing their movie tastes. \n",
    "\n",
    "In this example, we'll assume we already have pre-computed movie vectors which are held constant. User vectors are updated over time as new rating information is recieved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113be8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class UserVector(Operator):\n",
    "    \n",
    "    def __init__(self, schema, movie_vectors_file): \n",
    "        self.user_ratings = {}\n",
    "        self.movie_vectors = pd.read_csv(movie_vectors_file)\n",
    "        \n",
    "        super().__init__(schema)\n",
    "    \n",
    "    def on_record(self, record: Record):\n",
    "        # TODO: add ALS thing \n",
    "        output_record = Record(user=record.user, user_vector=np.array([1, 2, 3]))\n",
    "        return output_record  \n",
    "    \n",
    "user_schema = Schema(\n",
    "    primary_key=\"user\", columns={\"user\": str, \"user_vector\": np.array}\n",
    ")\n",
    "user_vectors = source.map(UserVector, args=(user_schema, \"movie_vectors.csv\"))\n",
    "user_vectors.as_queryable(\"user_vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708e7fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ralf_server.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7371d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ralf_client.bulk_query(table_name=\"user_vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224976b8",
   "metadata": {},
   "source": [
    "## Prioritizing Active Users \n",
    "Ralf allows for key-level prioritization policies. Say that we want to prioritize computing updates to user vectors for users who especially active. We can use activity data to implement a prioritized lottery scheduling policy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfb7aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_activity = pd.read_csv(\"user_active_time.csv\")\n",
    "user_activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc70322",
   "metadata": {},
   "source": [
    "For example, we can set the subsampling rate of the data to be inversely proportional to how active the user is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d322af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleActiveUsers(LoadSheddingPolicy):\n",
    "    \n",
    "    def __init__(self, user_activity_csv):\n",
    "        user_activity = pd.read_csv(\"user_active_time.csv\")\n",
    "        self.weights = user_activity.set_index(\"user_id\")[\"activity\"].to_dict()\n",
    "\n",
    "    def process(record: Record): \n",
    "        return random.random() < self.weights[record.user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705d2041",
   "metadata": {},
   "source": [
    "Alternatively, we can create a key prioritization policy which prioritizes keys uses lottery scheduling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41549bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ralf import PrioritizationPolicy\n",
    "\n",
    "# NOTE: this one doesn't work yet please just mentally visualize \n",
    "\n",
    "class LotteryScheduling(PrioritizationPolicy): \n",
    "    \n",
    "    def __init__(self, user_activity_csv): \n",
    "        user_activity = pd.read_csv(\"user_active_time.csv\")\n",
    "        self.weights = user_activity.set_index(\"user_id\")[\"activity\"].to_dict()\n",
    "        \n",
    "    def choose(self, keys: List[KeyType]): \n",
    "        # TODO: implement prioritized lottery scheduling \n",
    "        return random.choose(keys)\n",
    "\n",
    "user_vectors.add_prioritization_policy(lottery_scheduling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-suite",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risecamp-2021",
   "language": "python",
   "name": "risecamp-2021"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
