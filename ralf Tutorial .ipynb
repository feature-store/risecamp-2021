{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17006a17",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "This tutorial will go through how to setup a featurization pipeline in `ralf`. We'll setup a pipeline for computing user features given a data stream of user ratings. We'll then query the user features to predict the rating a user will give a movie. \n",
    "\n",
    "To do so, we'll do the following: \n",
    "1. Create feature tables from the movie lens dataset which are incrementally maintained by `ralf`\n",
    "2. Create a ralf client which queries the feature tables \n",
    "3. Implement load shedding policies to reduce feature computation cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a769d63d",
   "metadata": {},
   "source": [
    "# Creating a featurization pipeline \n",
    "We create a instance of ralf to that we can start creating tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05405be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ralf_server = Ralf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644ace1a",
   "metadata": {},
   "source": [
    "### Creating Source Tables\n",
    "Source tables define the raw data sources that are run through ralf to become features. `ralf` lets you create both static batch (e.g. from a CSV) and dynamic streaming sources (e.g. from Kafka). \n",
    "\n",
    "To define a source, we implement a `SourceOperator`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9df22df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingsSource(SourceOperator):\n",
    "    \n",
    "    def __init__(self, schema, kafka_topic):\n",
    "        self.topic = kafka_topic\n",
    "        \n",
    "    def next(): \n",
    "        pass "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f1523f",
   "metadata": {},
   "source": [
    "We specify a schema using ralf's `Schema` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1364670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ralf import Schema \n",
    "\n",
    "source_schema = Schema({\"user\", {\"user\": int, \"movie\": int, \"rating\": float}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6199eca",
   "metadata": {},
   "source": [
    "We can now add the source to our ralf instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c678ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = ralf_server.create_source(SourceOperator, args=(source_schema, \"ratings_topic\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3909f7f7",
   "metadata": {},
   "source": [
    "### Creating Feature Tables \n",
    "Now that we have data streaming into ralf through the source table, we can define derived feature tables from the source table. \n",
    "\n",
    "Feature tables follow an API similar to pandas dataframes. We define feature tables in terms of 1-2 parent tables and an operator which specifies how to transform parent data. \n",
    "\n",
    "\n",
    "For example, we can calculate the average rating for each user with an `AverageRating` operator: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ac4581",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageRating(Operator): \n",
    "    \n",
    "    def __init__(self, schema): \n",
    "        self.user_ratings = defaultdict(list)\n",
    "    \n",
    "    def on_record(record: Record): \n",
    "        self.user_ratings[record.user].append(record.rating)\n",
    "        ratings = np.array(self.user_ratings[record.user])\n",
    "        return Record(user=record.user, average=ratings.mean())     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c03ecef",
   "metadata": {},
   "source": [
    "The `AverageRating` operator can be used to define a feature table containing the average rating for each user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6f3c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_rating_schema = Schema({\"user\", {\"user\": int, \"average\": float}})\n",
    "average_rating = source.map(AverageRating, args=(averge_rating_schema))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6651c9",
   "metadata": {},
   "source": [
    "### Adding Processing Policies\n",
    "In many cases, we may only need to sub-sample some of the data to get the features we need. We can add a simple load shedding policy to the `average_rating` table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d18c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleHalf(LoadSheddingPolicy):\n",
    "\n",
    "    def process(record: Record) -> Boolean: \n",
    "        return random.random() < 0.5\n",
    "\n",
    "average_rating.add_load_shedding(SampleHalf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7715b4b9",
   "metadata": {},
   "source": [
    "## Creating a `ralf` Client \n",
    "Now that we have a simple pipeline, we can query the ralf server for features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbc90c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ralf_client = RalfClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b9cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ralf_client.point_query(table=\"average\", key=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbde8a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ralf_client.bulk_query(table=\"average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69ee3a4",
   "metadata": {},
   "source": [
    "# Advanced: Maintaining user vectors \n",
    "Now that we've setup a simple feature table and run some queries, we can create a more realistic feature table: a user vector representing their movie tastes. \n",
    "\n",
    "In this example, we'll assume we already have pre-computed movie vectors which are held constant. User vectors are updated over time as new rating informatio is recieved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113be8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserVectors(Operator):\n",
    "    \n",
    "    def __init__(self, schema, movie_vectors_file): \n",
    "        self.user_ratings = {}\n",
    "        self.movie_vectors = pd.read_csv(movie_vectors_file)\n",
    "    \n",
    "    def on_record(self, rating: Record, movie_vector: Record):\n",
    "        pass \n",
    "    \n",
    "user_vectors = source.map(UserVector(user_schema, \"movie_vectors.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224976b8",
   "metadata": {},
   "source": [
    "## Prioritizing Active Users \n",
    "Ralf allows for key-level prioritization policies. Say that we want to prioritize computing updates to user vectors for users who especially active. We can use activity data to implement a prioritized lottery scheduling policy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfb7aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_activity = pd.read_csv(\"user_active_time.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc70322",
   "metadata": {},
   "source": [
    "For example, we can set the subsampling rate of the data to be inversely proportional to how active the user is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d322af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleActiveUsers(LoadSheddingPolicy):\n",
    "    \n",
    "    def __init__(self, user_activity_csv):\n",
    "        user_activity = pd.read_csv(\"user_active_time.csv\")\n",
    "        self.weights = {}\n",
    "\n",
    "    def process(record: Record) -> Boolean: \n",
    "        return random.random() < self.weights[record.user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705d2041",
   "metadata": {},
   "source": [
    "Alternatively, we can create a key prioritization policy which prioritizes keys uses lottery scheduling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41549bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LotteryScheduling(PrioritizationPolicy): \n",
    "    \n",
    "    def __init__(self, user_activity_csv): \n",
    "        user_activity = pd.read_csv(\"user_active_time.csv\")\n",
    "        self.weights = user_activity.dict()\n",
    "        \n",
    "    def choose(self, keys: List[KeyType]): \n",
    "        pass    \n",
    "\n",
    "user_vectors.add_prioritization_policy(lottery_scheduling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4294a8e6",
   "metadata": {},
   "source": [
    "## Updating features lazily\n",
    "We need append tables for this.... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bddf0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
